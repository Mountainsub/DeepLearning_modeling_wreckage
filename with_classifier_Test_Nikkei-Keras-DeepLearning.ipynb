{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import module list is independent on respective file.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import yfinance as yf\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from datetime import date as date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.stats import mstats\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import japanize_matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "from datetime import date \n",
    "def get_nth_week(day):\n",
    "    return (day - 1) // 7 + 1\n",
    "\n",
    "def get_nth_dow(year, month, day):\n",
    "    return get_nth_week(day), calendar.weekday(year, month, day)\n",
    "\n",
    "def get_day_of_nth_dow(year, month, nth, dow):\n",
    "    '''dow: Monday(0) - Sunday(6)'''\n",
    "    if nth < 1 or dow < 0 or dow > 6:\n",
    "        return None\n",
    "\n",
    "    first_dow, n = calendar.monthrange(year, month)\n",
    "    day = 7 * (nth - 1) + (dow - first_dow) % 7 + 1\n",
    "\n",
    "    return day if day <= n else None\n",
    "def get_nth_dow_datetime_dt(dt):\n",
    "    return get_nth_week(dt.day), dt.weekday()\n",
    "def get_nth_dow_datetime(year, month, day):\n",
    "    return get_nth_week(day), date(year, month, day).weekday()\n",
    "\n",
    "def get_date_of_nth_dow(year, month, nth, dow):\n",
    "    day = get_day_of_nth_dow(year, month, nth, dow)\n",
    "    return date(year, month, day) if day else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jabond = pd.read_csv('data/JA_Bond_day.csv',index_col=0, parse_dates=True, encoding='cp932')['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjabond\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m jabond\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data['jabond'] = jabond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/訓練データ_20241030.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kerasを使って　分類モデルを作ろう!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from scipy.stats import mstats\n",
    "import japanize_matplotlib\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature(data, window_size):\n",
    "    window_data = []\n",
    "    X, Y = [], []\n",
    "    \n",
    "    if len(data) - window_size >= 1:\n",
    "        \n",
    "        for i in range(len(data)-window_size):\n",
    "            window = data[i:i+window_size]\n",
    "\n",
    "            X.append(window)\n",
    "\n",
    "            Y.append(data[i + window_size - 1])\n",
    "            \n",
    "            #window_data.append(window)\n",
    "    else:\n",
    "        for i in range(len(data)-window_size+1):\n",
    "            window = data[i:i+window_size]\n",
    "            #window_data.append(window)\n",
    "            \n",
    "    \n",
    "            X.append(window)\n",
    "\n",
    "            Y.append(data[i + window_size - 1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # [[], []. []......]\n",
    "    print(np.array(X))\n",
    "    return (np.array(X).reshape(-1, window_size, 1), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def lstm_comp(df):\n",
    "  # 入力層/中間層/出力層のネットワーク構築\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(256, activation='relu', batch_input_shape=(None, df.shape[1], df.shape[2])))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  # ネットワークのコンパイル\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "  return model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 38)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1813\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1813\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                       </span>┃<span style=\"font-weight: bold\"> Output Shape                  </span>┃<span style=\"font-weight: bold\">     Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│ lstm_1809 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
       "│ dropout_1804 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
       "│ dense_1804 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│ lstm_1809 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   │      \u001b[38;5;34m66,560\u001b[0m │\n",
       "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
       "│ dropout_1804 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   │           \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────┼───────────────────────────────┼─────────────┤\n",
       "│ dense_1804 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │         \u001b[38;5;34m129\u001b[0m │\n",
       "└────────────────────────────────────┴───────────────────────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,069</span> (781.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m200,069\u001b[0m (781.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,689</span> (260.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,689\u001b[0m (260.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,380</span> (521.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m133,380\u001b[0m (521.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lstm_pred(df):\n",
    "    model = Sequential()\n",
    "\n",
    "    length = df.shape[1]#X_train.shape[1]\n",
    "    hidden_layers = 128\n",
    "    in_out_neurons = 1\n",
    "    length_of_sequences = df.shape[0]\n",
    "    #model.add(Embedding(input_dim=length, output_dim=256, input_length=5))\n",
    "    model.add(LSTM(hidden_layers,\n",
    "                   #batch_size=32,\n",
    "                   input_shape=(length_of_sequences, in_out_neurons),\n",
    "                   return_sequences=False,\n",
    "                 stateful=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(hidden_layers, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "      \n",
    "    \n",
    "    # 1 or 9\n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=5, # ここで指定したエポック数の間改善がないと停止\n",
    "                           verbose=1,\n",
    "                           mode='max')\n",
    "            ]\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "TimeSeriesSplit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19]), array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "       37, 38]))\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38]), array([39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
      "       56, 57]))\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57]), array([58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,\n",
      "       75, 76]))\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76]), array([77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93,\n",
      "       94, 95]))\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]), array([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "       109, 110, 111, 112, 113, 114]))\n"
     ]
    }
   ],
   "source": [
    "folds = TimeSeriesSplit(5)\n",
    "for i in folds.split(df):\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "        85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]),\n",
       " array([ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
       "        109, 110, 111, 112, 113, 114]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list(folds.split(df))[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(folds.split(y[:train_len+i].values))[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4fb4a6680b4a5ca13c18676725c2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.4375 - val_loss: 0.5000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.4375 - val_loss: 0.5000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.4375 - val_loss: 0.5000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4375 - val_loss: 0.5000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.4375 - val_loss: 0.5000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
      "1\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.4706 - val_loss: 0.5000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.4706 - val_loss: 0.5000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4706 - val_loss: 0.5000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4706 - val_loss: 0.5000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4706 - val_loss: 0.5000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "2\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.4444 - val_loss: 1.0000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.4444 - val_loss: 1.0000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.4444 - val_loss: 1.0000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.4444 - val_loss: 1.0000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.4444 - val_loss: 1.0000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step\n",
      "3\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.4737 - val_loss: 1.0000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4737 - val_loss: 1.0000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.4737 - val_loss: 1.0000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4737 - val_loss: 1.0000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.4737 - val_loss: 1.0000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
      "4\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step\n",
      "5\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.5000 - val_loss: 1.0000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "6\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5238 - val_loss: 0.6667\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5238 - val_loss: 0.6667\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5238 - val_loss: 0.6667\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5238 - val_loss: 0.6667\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5238 - val_loss: 0.6667\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "7\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.5455 - val_loss: 0.3333\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.5455 - val_loss: 0.3333\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.5455 - val_loss: 0.3333\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.5455 - val_loss: 0.3333\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.5455 - val_loss: 0.3333\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "8\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5652 - val_loss: 0.0000e+00\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.5652 - val_loss: 0.0000e+00\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5652 - val_loss: 0.0000e+00\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5652 - val_loss: 0.0000e+00\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5652 - val_loss: 0.0000e+00\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "9\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5417 - val_loss: 0.0000e+00\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5417 - val_loss: 0.0000e+00\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.5417 - val_loss: 0.0000e+00\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5417 - val_loss: 0.0000e+00\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5417 - val_loss: 0.0000e+00\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "10\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.5200 - val_loss: 0.3333\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.5200 - val_loss: 0.3333\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.5200 - val_loss: 0.3333\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.5200 - val_loss: 0.3333\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.5200 - val_loss: 0.3333\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
      "11\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.5200 - val_loss: 0.2500\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5200 - val_loss: 0.2500\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.5200 - val_loss: 0.2500\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5200 - val_loss: 0.2500\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.5200 - val_loss: 0.2500\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
      "12\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "13\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.4815 - val_loss: 0.5000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4815 - val_loss: 0.5000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4815 - val_loss: 0.5000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4815 - val_loss: 0.5000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4815 - val_loss: 0.5000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
      "14\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5000 - val_loss: 0.2500\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "15\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.4828 - val_loss: 0.5000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4828 - val_loss: 0.5000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4828 - val_loss: 0.5000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4828 - val_loss: 0.5000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4828 - val_loss: 0.5000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "16\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.4667 - val_loss: 0.5000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.4667 - val_loss: 0.5000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4667 - val_loss: 0.5000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4667 - val_loss: 0.5000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4667 - val_loss: 0.5000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "17\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.4667 - val_loss: 0.4000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.4667 - val_loss: 0.4000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.4667 - val_loss: 0.4000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.4667 - val_loss: 0.4000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4667 - val_loss: 0.4000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
      "18\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.4839 - val_loss: 0.4000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4839 - val_loss: 0.4000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4839 - val_loss: 0.4000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4839 - val_loss: 0.4000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4839 - val_loss: 0.4000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "19\n",
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.4688 - val_loss: 0.4000\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4688 - val_loss: 0.4000\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4688 - val_loss: 0.4000\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.4688 - val_loss: 0.4000\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4688 - val_loss: 0.4000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
      "20\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 298ms/step - loss: 0.6458 - val_loss: 0.4000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6458 - val_loss: 0.4000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6458 - val_loss: 0.4000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6458 - val_loss: 0.4000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6458 - val_loss: 0.4000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "21\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 303ms/step - loss: 0.6250 - val_loss: 0.4000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4792 - val_loss: 0.4000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6250 - val_loss: 0.4000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4792 - val_loss: 0.4000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4792 - val_loss: 0.4000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
      "22\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 298ms/step - loss: 0.5139 - val_loss: 0.4000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5139 - val_loss: 0.4000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3333 - val_loss: 0.4000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4236 - val_loss: 0.4000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4236 - val_loss: 0.4000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "23\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 297ms/step - loss: 0.5139 - val_loss: 0.3333\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4236 - val_loss: 0.3333\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4236 - val_loss: 0.3333\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4236 - val_loss: 0.3333\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5139 - val_loss: 0.3333\n",
      "Epoch 5: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "24\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - loss: 0.4792 - val_loss: 0.1667\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4792 - val_loss: 0.1667\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4792 - val_loss: 0.1667\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4792 - val_loss: 0.1667\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4792 - val_loss: 0.1667\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "25\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 320ms/step - loss: 0.4458 - val_loss: 0.1667\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4000 - val_loss: 0.1667\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4458 - val_loss: 0.1667\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4458 - val_loss: 0.1667\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4917 - val_loss: 0.1667\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "26\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 358ms/step - loss: 0.4444 - val_loss: 0.1667\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5486 - val_loss: 0.1667\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4792 - val_loss: 0.1667\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4444 - val_loss: 0.1667\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4792 - val_loss: 0.1667\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "27\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 331ms/step - loss: 0.4821 - val_loss: 0.3333\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4286 - val_loss: 0.3333\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4554 - val_loss: 0.3333\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4554 - val_loss: 0.3333\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4554 - val_loss: 0.3333\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
      "28\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - loss: 0.4792 - val_loss: 0.5000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4375 - val_loss: 0.5000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4792 - val_loss: 0.5000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4167 - val_loss: 0.5000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4583 - val_loss: 0.5000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "29\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - loss: 0.4167 - val_loss: 0.4286\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4167 - val_loss: 0.4286\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4792 - val_loss: 0.4286\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4375 - val_loss: 0.4286\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4167 - val_loss: 0.4286\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
      "30\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 298ms/step - loss: 0.4398 - val_loss: 0.4286\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4398 - val_loss: 0.4286\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4398 - val_loss: 0.4286\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4398 - val_loss: 0.4286\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4236 - val_loss: 0.4286\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
      "31\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 311ms/step - loss: 0.4000 - val_loss: 0.5714\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4375 - val_loss: 0.5714\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4500 - val_loss: 0.5714\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4375 - val_loss: 0.5714\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4375 - val_loss: 0.5714\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "32\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - loss: 0.4129 - val_loss: 0.5714\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4223 - val_loss: 0.5714\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4223 - val_loss: 0.5714\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4223 - val_loss: 0.5714\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4318 - val_loss: 0.5714\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
      "33\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 297ms/step - loss: 0.4167 - val_loss: 0.5714\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4306 - val_loss: 0.5714\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4375 - val_loss: 0.5714\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4306 - val_loss: 0.5714\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4375 - val_loss: 0.5714\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
      "34\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 302ms/step - loss: 0.4455 - val_loss: 0.4286\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4407 - val_loss: 0.4286\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4455 - val_loss: 0.4286\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4407 - val_loss: 0.4286\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4407 - val_loss: 0.4286\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "35\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379ms/step - loss: 0.4359 - val_loss: 0.5000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.4503 - val_loss: 0.5000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4407 - val_loss: 0.5000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4455 - val_loss: 0.5000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4503 - val_loss: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "36\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - loss: 0.4554 - val_loss: 0.3750\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4554 - val_loss: 0.3750\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4613 - val_loss: 0.3750\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4583 - val_loss: 0.3750\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4613 - val_loss: 0.3750\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
      "37\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - loss: 0.4500 - val_loss: 0.3750\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4458 - val_loss: 0.3750\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4472 - val_loss: 0.3750\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4472 - val_loss: 0.3750\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4486 - val_loss: 0.3750\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "38\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 308ms/step - loss: 0.4375 - val_loss: 0.3750\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4375 - val_loss: 0.3750\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4375 - val_loss: 0.3750\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.4375 - val_loss: 0.3750\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4375 - val_loss: 0.3750\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step\n",
      "39\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 322ms/step - loss: 0.4485 - val_loss: 0.2500\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4473 - val_loss: 0.2500\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4473 - val_loss: 0.2500\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4461 - val_loss: 0.2500\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4498 - val_loss: 0.2500\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "40\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 299ms/step - loss: 0.4375 - val_loss: 0.2500\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4375 - val_loss: 0.2500\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4421 - val_loss: 0.2500\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4421 - val_loss: 0.2500\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4375 - val_loss: 0.2500\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "41\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 453ms/step - loss: 0.4375 - val_loss: 0.3333\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4398 - val_loss: 0.3333\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4398 - val_loss: 0.3333\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.4398 - val_loss: 0.3333\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4398 - val_loss: 0.3333\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step\n",
      "42\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 302ms/step - loss: 0.4627 - val_loss: 0.3333\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4529 - val_loss: 0.3333\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4463 - val_loss: 0.3333\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4496 - val_loss: 0.3333\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4463 - val_loss: 0.3333\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
      "43\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 302ms/step - loss: 0.4292 - val_loss: 0.4444\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4375 - val_loss: 0.4444\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4500 - val_loss: 0.4444\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4375 - val_loss: 0.4444\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4375 - val_loss: 0.4444\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
      "44\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 304ms/step - loss: 0.4504 - val_loss: 0.4444\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4603 - val_loss: 0.4444\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4653 - val_loss: 0.4444\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4405 - val_loss: 0.4444\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4603 - val_loss: 0.4444\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
      "45\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - loss: 0.4659 - val_loss: 0.4444\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4489 - val_loss: 0.4444\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4545 - val_loss: 0.4444\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4375 - val_loss: 0.4444\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4375 - val_loss: 0.4444\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
      "46\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 314ms/step - loss: 0.4556 - val_loss: 0.4444\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4366 - val_loss: 0.4444\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4239 - val_loss: 0.4444\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4112 - val_loss: 0.4444\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4366 - val_loss: 0.4444\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "47\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 364ms/step - loss: 0.4176 - val_loss: 0.5000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4366 - val_loss: 0.5000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4239 - val_loss: 0.5000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4366 - val_loss: 0.5000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4366 - val_loss: 0.5000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
      "48\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 350ms/step - loss: 0.4167 - val_loss: 0.5000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4444 - val_loss: 0.5000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4167 - val_loss: 0.5000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4167 - val_loss: 0.5000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4375 - val_loss: 0.5000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "49\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 390ms/step - loss: 0.4250 - val_loss: 0.6000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4175 - val_loss: 0.6000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4025 - val_loss: 0.6000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4100 - val_loss: 0.6000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4250 - val_loss: 0.6000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
      "50\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 327ms/step - loss: 0.4119 - val_loss: 0.7000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4199 - val_loss: 0.7000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4038 - val_loss: 0.7000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4359 - val_loss: 0.7000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4038 - val_loss: 0.7000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
      "51\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 325ms/step - loss: 0.4529 - val_loss: 0.7000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4190 - val_loss: 0.7000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4529 - val_loss: 0.7000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4529 - val_loss: 0.7000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4105 - val_loss: 0.7000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "52\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 303ms/step - loss: 0.4345 - val_loss: 0.7000\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4524 - val_loss: 0.7000\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4256 - val_loss: 0.7000\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4256 - val_loss: 0.7000\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4524 - val_loss: 0.7000\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "53\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - loss: 0.4077 - val_loss: 0.7273\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4792 - val_loss: 0.7273\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.4435 - val_loss: 0.7273\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4613 - val_loss: 0.7273\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4435 - val_loss: 0.7273\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
      "54\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 333ms/step - loss: 0.4411 - val_loss: 0.6364\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4411 - val_loss: 0.6364\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4131 - val_loss: 0.6364\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4411 - val_loss: 0.6364\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4598 - val_loss: 0.6364\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
      "55\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334ms/step - loss: 0.4375 - val_loss: 0.6364\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.4569 - val_loss: 0.6364\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4375 - val_loss: 0.6364\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4083 - val_loss: 0.6364\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4181 - val_loss: 0.6364\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
      "56\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - loss: 0.4321 - val_loss: 0.7273\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4220 - val_loss: 0.7273\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4422 - val_loss: 0.7273\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4523 - val_loss: 0.7273\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4321 - val_loss: 0.7273\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "57\n",
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 336ms/step - loss: 0.4271 - val_loss: 0.7273\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4688 - val_loss: 0.7273\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4375 - val_loss: 0.7273\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4271 - val_loss: 0.7273\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4583 - val_loss: 0.7273\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "58\n",
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - loss: 0.5391 - val_loss: 0.7273\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5469 - val_loss: 0.7273\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5312 - val_loss: 0.7273\n",
      "Epoch 4/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4049 - val_loss: 0.7273\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5312 - val_loss: 0.7273\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "59\n",
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.5469 - val_loss: 0.6667\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5312 - val_loss: 0.6667\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5391 - val_loss: 0.6667\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5391 - val_loss: 0.6667\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5156 - val_loss: 0.6667\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "60\n",
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 195ms/step - loss: 0.4792 - val_loss: 0.6667\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5143 - val_loss: 0.6667\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5299 - val_loss: 0.6667\n",
      "Epoch 4/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4323 - val_loss: 0.6667\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3581 - val_loss: 0.6667\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
      "61\n",
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 195ms/step - loss: 0.4601 - val_loss: 0.6667\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4371 - val_loss: 0.6667\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4757 - val_loss: 0.6667\n",
      "Epoch 4/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4293 - val_loss: 0.6667\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3828 - val_loss: 0.6667\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "62\n",
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.4245 - val_loss: 0.6667\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4648 - val_loss: 0.6667\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5052 - val_loss: 0.6667\n",
      "Epoch 4/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4557 - val_loss: 0.6667\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4323 - val_loss: 0.6667\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
      "63\n",
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - loss: 0.4565 - val_loss: 0.5833\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4893 - val_loss: 0.5833\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4253 - val_loss: 0.5833\n",
      "Epoch 4/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4487 - val_loss: 0.5833\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4737 - val_loss: 0.5833\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
      "64\n",
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.4601 - val_loss: 0.5833\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4536 - val_loss: 0.5833\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4787 - val_loss: 0.5833\n",
      "Epoch 4/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4740 - val_loss: 0.5833\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4631 - val_loss: 0.5833\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "65\n",
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - loss: 0.4553 - val_loss: 0.6154\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5221 - val_loss: 0.6154\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4787 - val_loss: 0.6154\n",
      "Epoch 4/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5082 - val_loss: 0.6154\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4740 - val_loss: 0.6154\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
      "66\n",
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 173ms/step - loss: 0.4634 - val_loss: 0.6154\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4946 - val_loss: 0.6154\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5015 - val_loss: 0.6154\n",
      "Epoch 4/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4790 - val_loss: 0.6154\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4634 - val_loss: 0.6154\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (67, 1), indices imply (93, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 108\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rate_prediction, index\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mindex[train_len\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m11\u001b[39m:], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 782\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    783\u001b[0m             data,\n\u001b[0;32m    784\u001b[0m             index,\n\u001b[0;32m    785\u001b[0m             columns,\n\u001b[0;32m    786\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    787\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    788\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    789\u001b[0m         )\n\u001b[0;32m    791\u001b[0m \u001b[38;5;66m# For data is list-like, or Iterable (will consume into list)\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{passed}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{implied}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (67, 1), indices imply (82, 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 110\u001b[0m\n\u001b[0;32m    108\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rate_prediction, index\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mindex[train_len\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m11\u001b[39m:], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rate_prediction, index\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mindex[train_len\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    111\u001b[0m precision \u001b[38;5;241m=\u001b[39m matthews_corrcoef(Ys[:], rate_prediction)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precision \u001b[38;5;241m>\u001b[39m precision1:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    771\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;66m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39m\n\u001b[0;32m    773\u001b[0m             \u001b[38;5;66m# attribute \"name\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    779\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    780\u001b[0m         )\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 782\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    783\u001b[0m             data,\n\u001b[0;32m    784\u001b[0m             index,\n\u001b[0;32m    785\u001b[0m             columns,\n\u001b[0;32m    786\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    787\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    788\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    789\u001b[0m         )\n\u001b[0;32m    791\u001b[0m \u001b[38;5;66m# For data is list-like, or Iterable (will consume into list)\u001b[39m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{passed}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{implied}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (67, 1), indices imply (93, 1)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "train_data = data.dropna()\n",
    "precision1 = 0\n",
    "train_len = 400\n",
    "dataY = pd.DataFrame()\n",
    "for seed in range(0, 7, 1):\n",
    "    folds = TimeSeriesSplit(5)\n",
    "    for skip in [30]:\n",
    "        # 買いの場合　5日、50日\n",
    "        # 売りの場合　3%\n",
    "        dic = {}\n",
    "        Ys = []\n",
    "        for Date in ['2012-12-01']:#, '2015-06-01', '2015-09-01', '2015-12-01']:\n",
    "            train_data['class'] = (train_data['現物'].pct_change(periods=skip) > train_data['現物'].pct_change(periods=skip).describe()['50%']).astype(int)\n",
    "            #train_data=data.dropna(subset=['BPS指数ベース','利回り指数ベース', 'SCFI', '売り残', '買い残'])\n",
    "\n",
    "            df = train_data[::]\n",
    "            train_len = df.shape[0] // 2\n",
    "            DATE = pd.to_datetime('2021-01-29') - relativedelta(weeks=skip)\n",
    "            df = df.loc[DATE:, :]\n",
    "            \n",
    "            y = df.loc[DATE:, 'class'][skip:]\n",
    "            \n",
    "            # 欠損値を列の1つ手前の値で埋める\n",
    "            %matplotlib inline\n",
    "\n",
    "\n",
    "            df = df.fillna(method='ffill')\n",
    "\n",
    "            \n",
    "\n",
    "            #訓練データを説明変数データ(X_train)と目的変数データ(y_train)に分割\n",
    "\n",
    "            for num1 in [0.002]:\n",
    "\n",
    "                # Old 250日前比較の変化分、 300日の変化分、 350日の変化分、425日の変化分、450日の変化分 \n",
    "                # ['Bond_400', 'Bond_225', 'Bond_250', 'Bond_125', 'Bond_350']\n",
    "                # ['PER加重平均', 'PER指数ベース', 'PBR加重平均', 'PBR指数ベース', 'EPS加重平均', 'EPS指数ベース', 'BPS加重平均', 'BPS指数ベース']\n",
    "                # 'PBR指数ベース', 'EPS指数ベース'\n",
    "                A = df.drop(['class'], axis=1)[['PBR指数ベース', 'EPS指数ベース']].dropna().replace(-np.inf, 0).replace(np.inf, 0)\n",
    "                # 'PER指数ベース', 'BPS指数ベース', '利回り指数ベース', 'jabond',  'SCFI', 'CCFI', 'バルチック海運指数 BADI'\n",
    "                # 'BPS指数ベース', '利回り指数ベース', 'SCFI'\n",
    "                B = df.drop(['class'], axis=1)[['BPS指数ベース','利回り指数ベース', 'SCFI', '売り残']].sample(2, random_state=seed, axis=1).dropna().replace(-np.inf, 0).replace(np.inf, 0)\n",
    "                #X = pd.concat([A, B], axis=1).dropna().loc['2021-01-29':, :]\n",
    "                \n",
    "                cols =['先物合計','売り残', '売り残前回比', '買い残', '買い残前回比', '比率3', 'ラージ', 'ミニ',  'SCFI', \n",
    "                       'PER指数ベース1wChange', 'PBR指数ベース1wChange', '利回り指数ベース1wChange', 'EPS指数ベース1wChange','BPS指数ベース1wChange', '累積']\n",
    "                \n",
    "                X = df.loc['2021-01-29':, cols].replace(-np.inf, 0).replace(np.inf, 0).sample(12, random_state=seed, axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                train_len = 19\n",
    "\n",
    "\n",
    "                rate_prediction = []\n",
    "                \n",
    "                #X = df.drop(['class'], axis=1)\n",
    "\n",
    "                for i in tqdm(range(0,len(y)-train_len+1, 1)):\n",
    "                    print(i)\n",
    "                    try:\n",
    "                        indexes = list(folds.split(X[:train_len+i].values))[4]\n",
    "                        X_train, X_test, y_train, y_test = X[:train_len+i].values[indexes[0]], X[:train_len+i].values[indexes[1]], y[:train_len+i].values[indexes[0]], y[:train_len+i].values[indexes[1]]\n",
    "                        #print(X_train, X_test, y_train, y_test)\n",
    "                        X_test, X_valid, y_test, y_valid = X_test[-1], X_test[:-1] ,y_test[-1], y_test[:-1]\n",
    "                    except Exception as e:\n",
    "                        print(e, X_test)\n",
    "                        continue\n",
    "                    model = lstm_pred(X[:train_len+i].values)\n",
    "                    # Winsorize top 1% and bottom 1% of points.\n",
    "                    # Apply on X_train and X_test separately\n",
    "                    '''\n",
    "                    X_train = mstats.winsorize(X_train, limits = [0.01, 0.01])\n",
    "                    X_predict = mstats.winsorize(X_predict, limits = [0.01, 0.01])\n",
    "                    '''\n",
    "\n",
    "\n",
    "                    model.fit(X_train,\n",
    "                              y_train, \n",
    "                              epochs=30, \n",
    "                              batch_size=32, \n",
    "                              validation_data=(X_valid, y_valid),\n",
    "                              callbacks=callbacks)\n",
    "\n",
    "                    \n",
    "                    # Make a prediction on testing data\n",
    "                    # [[],[],[],,,] -> [ , , ,]\n",
    "                    #plot_feature_importance(model.feature_importances_,X.columns,'CATBOOST')\n",
    "                    try:\n",
    "                        pred = model.predict(X_test.reshape(1, -1))\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        continue\n",
    "\n",
    "                    rate_prediction = np.append(rate_prediction, pred)\n",
    "                    Ys.append(y_test)\n",
    "                    precision = matthews_corrcoef(Ys, rate_prediction)\n",
    "                    #print(precision)\n",
    "                dic['No'] = seed\n",
    "                dic2 = {name:[1] if name in X.columns else [0] for name in cols}\n",
    "                dic.update(dic2)\n",
    "                dic['precision'] = precision\n",
    "                temp = pd.DataFrame(dic)\n",
    "                try:\n",
    "                    result = pd.DataFrame(rate_prediction, index=X.index[train_len+11:], columns=['predict'])\n",
    "                except:\n",
    "                    continue\n",
    "                    #result = pd.DataFrame(rate_prediction, index=X.index[train_len-1:-1], columns=['predict'])\n",
    "                precision = matthews_corrcoef(Ys[:], rate_prediction)\n",
    "                if precision > precision1:\n",
    "                    pair = ('corr:', precision, Date, X.columns, skip, seed)\n",
    "                    precision1 = precision\n",
    "                print('corr:', precision, Date, X.columns)\n",
    "            dataY = pd.concat([dataY, temp])\n",
    "            \n",
    "            print(result.sum()['predict'])\n",
    "\n",
    "\n",
    "\n",
    "result\n",
    "display(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日付</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-21</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-28</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-18</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-09</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-23</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-06</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-13</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-20</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            predict\n",
       "日付                 \n",
       "2022-01-07      1.0\n",
       "2022-01-14      1.0\n",
       "2022-01-21      1.0\n",
       "2022-01-28      1.0\n",
       "2022-02-18      1.0\n",
       "...             ...\n",
       "2024-08-09      1.0\n",
       "2024-08-23      1.0\n",
       "2024-09-06      1.0\n",
       "2024-09-13      1.0\n",
       "2024-09-20      1.0\n",
       "\n",
       "[82 rows x 1 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'現物', '先物合計'\n",
    "       '売り残', '売り残前回比', '買い残', '買い残前回比', '比率3', 'ラージ', 'ミニ',\n",
    "       'SCFI', 'PER加重平均1wChange', 'PER指数ベース1wChange',\n",
    "       'PBR加重平均1wChange', 'PBR指数ベース1wChange', '利回り単純計算1wChange',\n",
    "       '利回り指数ベース1wChange', 'EPS加重平均1wChange', 'EPS指数ベース1wChange',\n",
    "       'BPS加重平均1wChange', 'BPS指数ベース1wChange', '累積'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PER加重平均', 'PER指数ベース', 'PBR加重平均', 'PBR指数ベース', '利回り単純計算', '利回り指数ベース',\n",
       "       'EPS加重平均', 'EPS指数ベース', 'BPS加重平均', 'BPS指数ベース', '現物', '先物合計', '現物先物合計',\n",
       "       '売り残', '売り残前回比', '買い残', '買い残前回比', '差引', '比率', '比率2', '比率3', 'ラージ', 'ミニ',\n",
       "       'TOPIX', 'Date', 'SCFI', 'PER加重平均1wChange', 'PER指数ベース1wChange',\n",
       "       'PBR加重平均1wChange', 'PBR指数ベース1wChange', '利回り単純計算1wChange',\n",
       "       '利回り指数ベース1wChange', 'EPS加重平均1wChange', 'EPS指数ベース1wChange',\n",
       "       'BPS加重平均1wChange', 'BPS指数ベース1wChange', '累積', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict    82.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rate_prediction, index=X.index[train_len+11:], columns=['predict']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 15)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)), annot=True)\n",
    "plt.xlabel(\"pred\")\n",
    "plt.ylabel('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.mkdir('prediction')\n",
    "result.to_csv('prediction/20241026.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 計算用\n",
    "index=1\n",
    "# 資産のおきなおし\n",
    "\n",
    "\n",
    "def judge_message(message):\n",
    "    if message == 'crossed':\n",
    "        profitline, loss_cut = 'crossed', 'safe'\n",
    "    elif message == 'losscut.':\n",
    "        profitline, loss_cut = 'not crossed', 'Losscut.'\n",
    "    elif message != 'anomally':\n",
    "        profitline, loss_cut = 'not crossed', 'safe'\n",
    "    else:\n",
    "        profitline, loss_cut = 'anomally', 'anomally'\n",
    "    return (profitline, loss_cut)\n",
    "\n",
    "def judge_count(message):\n",
    "    if message == 'crossed':\n",
    "        profitline, loss_cut = 1, 0\n",
    "    elif message == 'losscut.':\n",
    "        profitline, loss_cut = 0, 1\n",
    "    else:\n",
    "        profitline, loss_cut = 0, 0\n",
    "    return (profitline, loss_cut)\n",
    "\n",
    "\n",
    "def order_pnl(data, idx, losscut_rate, reverse, ratio=1, bond_leverage=10, threshold=None, schedule=pd.read_csv('data/RSI.csv', index_col='Date', parse_dates=True), fee_on=True):\n",
    "\n",
    "    ind, ind2 = idx[0], idx[1]\n",
    "    try:\n",
    "        data = data.query('Date >= @ind & Date < @ind2').dropna(how='any', axis=0)\n",
    "        entry_price = (data.loc[ind:, \"Close\"]).values[0]\n",
    "        \n",
    "        Asset = (data).loc[ind:,\"Close\"].values[0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, None, None, None\n",
    "    # ↓not used\n",
    "    \n",
    "    fee = entry_price * 0.022 * 1e-2 * 2\n",
    "    return_value = 0\n",
    "    init = ratio\n",
    "    print(threshold)\n",
    "    pTake = entry_price*threshold\n",
    "    for i,temp in data.iterrows():\n",
    "      \n",
    "        \n",
    "        high_to_open = temp[\"High\"] - entry_price\n",
    "        open_to_low = entry_price - temp[\"Low\"]\n",
    "        if reverse: \n",
    "            \n",
    "            # sell order \n",
    "            director = -1\n",
    "            perspective_maxloss = high_to_open \n",
    "            # \n",
    "            ratio = init\n",
    "                \n",
    "        else:           \n",
    "            \n",
    "            # buy order\n",
    "            director = 1\n",
    "            perspective_maxloss = open_to_low\n",
    "            perspective_maxprofit = high_to_open\n",
    "            ratio = init\n",
    "            pass\n",
    "        \n",
    "        losscutsign =  perspective_maxloss > entry_price * (losscut_rate)\n",
    "        profitTakesign = perspective_maxprofit > pTake\n",
    "        if (not losscutsign) and (not profitTakesign): \n",
    "            continue\n",
    "        elif losscutsign:\n",
    "            return_value = -1 * entry_price*(losscut_rate) \n",
    "            print(\"check : Losscut.\")\n",
    "            return (return_value, 'losscut.', i, Asset) \n",
    "        elif profitTakesign:\n",
    "            print(\"check : ProfitTake\")\n",
    "            return pTake, 'crossed', i, Asset\n",
    "    \n",
    "    return_value = director*(temp['Close'] - entry_price)\n",
    "    return (return_value-fee, None, i, Asset) if fee_on else (return_value, None, i, Asset) \n",
    "\n",
    "\n",
    "# This code(function) yields to (temporary interest, temporary totalreturn),totalreturn, ideal Asset, and Last trade information, \n",
    "\n",
    "\n",
    "def calc(schedule, losscut, reverse, leverage, data2=None, ratio=1, bond_leverage=10, threshold=None, fee_on=True, pTake=pd.read_csv('data/VIsignals.csv',index_col=0, parse_dates=True)):\n",
    "\n",
    "    \n",
    "    # \"reverse\" were the opposite, then What score...?\n",
    "    if reverse:\n",
    "        schedule['predict'] = [0 if i == 1 else 1 for i in schedule['predict']]\n",
    "    # 月次でデータを取っているので、例えば売りのサイン(オーダー)のときにロスカットしてから\n",
    "    #schedule_entry = schedule.query('Date >= @schedule_entry').index[0]\n",
    "    \n",
    "    totalreturn = 0    \n",
    "    \n",
    "    losscut_count, profit_count = 0, 0\n",
    "    \n",
    "    dic = {}\n",
    "    df = pd.DataFrame()\n",
    "    Asset =1\n",
    "    Day =0\n",
    "    # 〇DATA ×DATE\n",
    "    for Day, row in schedule.iterrows(): \n",
    "        profitline ,loss_cut_sgn = \"not crossed\", \"safe\"\n",
    "        if row['predict'] == 0:\n",
    "            continue\n",
    "        \n",
    "        schedule_entry = Day \n",
    "        schedule_exit = schedule_entry+relativedelta(days=30) \n",
    "\n",
    "\n",
    "        \n",
    "        # SVM のorder_pnlとは中身が異なる\n",
    "        # ind, losscut_rate, profit_rate, predict, index=index, ratio=1\n",
    "        print(schedule_entry, schedule_exit)\n",
    "        profit, message, day, Asset = order_pnl(**{'data':data2, \n",
    "                                        'idx':(schedule_entry, schedule_exit), \n",
    "                                        'losscut_rate':losscut,  \n",
    "                                        'reverse':reverse, \n",
    "                                        'ratio':ratio,\n",
    "                                        'bond_leverage':bond_leverage,\n",
    "                                        'threshold':pTake.loc[schedule_entry, 'Close']*threshold*1e-2,\n",
    "                                        'fee_on':fee_on})\n",
    "\n",
    "        \n",
    "        profitline, loss_cut_sgn = judge_message(message)\n",
    "        losscut_count += judge_count(message)[1]\n",
    "\n",
    "\n",
    "        profit *= leverage\n",
    "        totalreturn += profit\n",
    "        Return = profit / Asset\n",
    "        Days = (day - schedule_entry).days\n",
    "        schedule = schedule.query('Date > @schedule_exit')\n",
    "        \n",
    "        \n",
    "        dic = {\"Return\":Return, \n",
    "               #\"profitline\":profitline,\n",
    "               \"loss_cut\":loss_cut_sgn,\n",
    "               \"profit\":profit,\n",
    "               \"Asset\":Asset,\n",
    "               \"Exit Date\":schedule_exit,\n",
    "                \"日数\":Days}\n",
    "\n",
    "        temp = pd.DataFrame(dic, index=[schedule_entry])\n",
    "        df = pd.concat([df,temp],axis=0)\n",
    "        \n",
    "\n",
    "            \n",
    "    print(f\"loss_cut: {losscut_count}\", f\"profit_count: {profit_count}\")\n",
    "    print(f\"totalreturn: {totalreturn}\", f\"asset: {Asset}\", f\"yield:{totalreturn / 1}\")\n",
    "\n",
    "    \n",
    "    return [None, df]\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Drawdown(profits):\n",
    "\n",
    "    # 単利運用での資産額の計算\n",
    "    total = 1 + np.cumsum(profits)\n",
    "\n",
    "    # 月ごとのそれまでの最大資産の計算\n",
    "    max_assets = pd.Series(total).cummax().values\n",
    "\n",
    "    # ドローダウンの計算\n",
    "    dd = max_assets - total\n",
    "\n",
    "    # 最大ドローダウンの計算\n",
    "    max_dd_percent = max(dd) * 100\n",
    "    print(f'最大ドローダウン: {max_dd_percent:.3f} %')\n",
    "    return max(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 売りはなし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日経買いOnlyはなし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-23 00:00:00 2021-05-23 00:00:00\n",
      "0.04\n",
      "2021-05-07 00:00:00 2021-06-06 00:00:00\n",
      "0.03696\n",
      "2021-05-21 00:00:00 2021-06-20 00:00:00\n",
      "0.0461\n",
      "2021-06-04 00:00:00 2021-07-04 00:00:00\n",
      "0.04156000000000001\n",
      "2021-06-18 00:00:00 2021-07-18 00:00:00\n",
      "0.0368\n",
      "2021-07-02 00:00:00 2021-08-01 00:00:00\n",
      "0.03370000000000001\n",
      "2021-07-16 00:00:00 2021-08-15 00:00:00\n",
      "0.03926\n",
      "2021-08-06 00:00:00 2021-09-05 00:00:00\n",
      "0.0391\n",
      "check : ProfitTake\n",
      "2021-08-20 00:00:00 2021-09-19 00:00:00\n",
      "0.04302\n",
      "check : ProfitTake\n",
      "2021-09-03 00:00:00 2021-10-03 00:00:00\n",
      "0.03858\n",
      "check : ProfitTake\n",
      "2021-09-17 00:00:00 2021-10-17 00:00:00\n",
      "0.04016\n",
      "2021-10-01 00:00:00 2021-10-31 00:00:00\n",
      "0.047880000000000006\n",
      "2021-10-15 00:00:00 2021-11-14 00:00:00\n",
      "0.04046\n",
      "2021-10-29 00:00:00 2021-11-28 00:00:00\n",
      "0.04376000000000001\n",
      "2021-11-12 00:00:00 2021-12-12 00:00:00\n",
      "0.038700000000000005\n",
      "2021-11-26 00:00:00 2021-12-26 00:00:00\n",
      "0.044660000000000005\n",
      "2021-12-10 00:00:00 2022-01-09 00:00:00\n",
      "0.04152\n",
      "2021-12-24 00:00:00 2022-01-23 00:00:00\n",
      "0.03758\n",
      "2022-01-14 00:00:00 2022-02-13 00:00:00\n",
      "0.0438\n",
      "2022-01-28 00:00:00 2022-02-27 00:00:00\n",
      "0.05412\n",
      "2022-02-18 00:00:00 2022-03-20 00:00:00\n",
      "0.0507\n",
      "2022-03-04 00:00:00 2022-04-03 00:00:00\n",
      "0.05598\n",
      "check : ProfitTake\n",
      "2022-03-18 00:00:00 2022-04-17 00:00:00\n",
      "0.05058\n",
      "check : ProfitTake\n",
      "2022-04-01 00:00:00 2022-05-01 00:00:00\n",
      "0.04254000000000001\n",
      "2022-04-15 00:00:00 2022-05-15 00:00:00\n",
      "0.04162\n",
      "2022-05-06 00:00:00 2022-06-05 00:00:00\n",
      "0.05546\n",
      "2022-05-20 00:00:00 2022-06-19 00:00:00\n",
      "0.04736\n",
      "check : ProfitTake\n",
      "2022-06-03 00:00:00 2022-07-03 00:00:00\n",
      "0.038020000000000005\n",
      "2022-06-17 00:00:00 2022-07-17 00:00:00\n",
      "0.05462\n",
      "2022-07-01 00:00:00 2022-07-31 00:00:00\n",
      "0.04882000000000001\n",
      "check : ProfitTake\n",
      "2022-07-15 00:00:00 2022-08-14 00:00:00\n",
      "0.043340000000000004\n",
      "check : ProfitTake\n",
      "2022-07-29 00:00:00 2022-08-28 00:00:00\n",
      "0.03786\n",
      "check : ProfitTake\n",
      "2022-08-12 00:00:00 2022-09-11 00:00:00\n",
      "0.03678000000000001\n",
      "2022-08-26 00:00:00 2022-09-25 00:00:00\n",
      "0.03744\n",
      "2022-09-09 00:00:00 2022-10-09 00:00:00\n",
      "0.03898\n",
      "2022-09-30 00:00:00 2022-10-30 00:00:00\n",
      "0.05266\n",
      "check : ProfitTake\n",
      "2022-10-14 00:00:00 2022-11-13 00:00:00\n",
      "0.04944\n",
      "2022-10-28 00:00:00 2022-11-27 00:00:00\n",
      "0.047400000000000005\n",
      "check : ProfitTake\n",
      "2022-11-11 00:00:00 2022-12-11 00:00:00\n",
      "0.04062\n",
      "2022-11-25 00:00:00 2022-12-25 00:00:00\n",
      "0.03498\n",
      "2022-12-09 00:00:00 2023-01-08 00:00:00\n",
      "0.03608\n",
      "2022-12-23 00:00:00 2023-01-22 00:00:00\n",
      "0.0404\n",
      "2023-01-06 00:00:00 2023-02-05 00:00:00\n",
      "0.03642\n",
      "check : ProfitTake\n",
      "2023-01-20 00:00:00 2023-02-19 00:00:00\n",
      "0.03474\n",
      "check : ProfitTake\n",
      "2023-02-03 00:00:00 2023-03-05 00:00:00\n",
      "0.03258\n",
      "2023-02-17 00:00:00 2023-03-19 00:00:00\n",
      "0.0308\n",
      "check : ProfitTake\n",
      "2023-03-03 00:00:00 2023-04-02 00:00:00\n",
      "0.032380000000000006\n",
      "2023-03-17 00:00:00 2023-04-16 00:00:00\n",
      "0.038900000000000004\n",
      "check : ProfitTake\n",
      "2023-03-31 00:00:00 2023-04-30 00:00:00\n",
      "0.03332\n",
      "2023-04-14 00:00:00 2023-05-14 00:00:00\n",
      "0.0332\n",
      "2023-04-28 00:00:00 2023-05-28 00:00:00\n",
      "0.030440000000000005\n",
      "check : ProfitTake\n",
      "2023-05-19 00:00:00 2023-06-18 00:00:00\n",
      "0.04014\n",
      "check : ProfitTake\n",
      "2023-06-02 00:00:00 2023-07-02 00:00:00\n",
      "0.040119999999999996\n",
      "check : ProfitTake\n",
      "2023-06-16 00:00:00 2023-07-16 00:00:00\n",
      "0.041479999999999996\n",
      "2023-06-30 00:00:00 2023-07-30 00:00:00\n",
      "0.038220000000000004\n",
      "2023-07-14 00:00:00 2023-08-13 00:00:00\n",
      "0.04098\n",
      "2023-07-28 00:00:00 2023-08-27 00:00:00\n",
      "0.03718\n",
      "2023-08-18 00:00:00 2023-09-17 00:00:00\n",
      "0.03904\n",
      "check : ProfitTake\n",
      "2023-09-01 00:00:00 2023-10-01 00:00:00\n",
      "0.03372\n",
      "2023-09-15 00:00:00 2023-10-15 00:00:00\n",
      "0.03198\n",
      "2023-09-29 00:00:00 2023-10-29 00:00:00\n",
      "0.0368\n",
      "2023-10-13 00:00:00 2023-11-12 00:00:00\n",
      "0.04194\n",
      "2023-10-27 00:00:00 2023-11-26 00:00:00\n",
      "0.04518\n",
      "check : ProfitTake\n",
      "2023-11-17 00:00:00 2023-12-17 00:00:00\n",
      "0.03656000000000001\n",
      "2023-12-01 00:00:00 2023-12-31 00:00:00\n",
      "0.032560000000000006\n",
      "2023-12-15 00:00:00 2024-01-14 00:00:00\n",
      "0.03468\n",
      "check : ProfitTake\n",
      "2023-12-29 00:00:00 2024-01-28 00:00:00\n",
      "0.03492000000000001\n",
      "check : ProfitTake\n",
      "2024-01-12 00:00:00 2024-02-11 00:00:00\n",
      "0.0448\n",
      "check : ProfitTake\n",
      "2024-01-26 00:00:00 2024-02-25 00:00:00\n",
      "0.03928\n",
      "check : ProfitTake\n",
      "2024-02-09 00:00:00 2024-03-10 00:00:00\n",
      "0.0385\n",
      "check : ProfitTake\n",
      "2024-03-01 00:00:00 2024-03-31 00:00:00\n",
      "0.041479999999999996\n",
      "2024-03-15 00:00:00 2024-04-14 00:00:00\n",
      "0.04066\n",
      "check : ProfitTake\n",
      "2024-03-29 00:00:00 2024-04-28 00:00:00\n",
      "0.037140000000000006\n",
      "2024-04-12 00:00:00 2024-05-12 00:00:00\n",
      "0.039939999999999996\n",
      "2024-04-26 00:00:00 2024-05-26 00:00:00\n",
      "0.04164\n",
      "2024-05-17 00:00:00 2024-06-16 00:00:00\n",
      "0.03358\n",
      "2024-05-31 00:00:00 2024-06-30 00:00:00\n",
      "0.03368\n",
      "check : ProfitTake\n",
      "2024-06-14 00:00:00 2024-07-14 00:00:00\n",
      "0.03258\n",
      "check : ProfitTake\n",
      "2024-06-28 00:00:00 2024-07-28 00:00:00\n",
      "0.03226\n",
      "check : ProfitTake\n",
      "2024-07-12 00:00:00 2024-08-11 00:00:00\n",
      "0.03674\n",
      "2024-07-26 00:00:00 2024-08-25 00:00:00\n",
      "0.0444\n",
      "2024-08-09 00:00:00 2024-09-08 00:00:00\n",
      "0.09056000000000002\n",
      "check : ProfitTake\n",
      "2024-08-23 00:00:00 2024-09-22 00:00:00\n",
      "0.050760000000000007\n",
      "2024-09-06 00:00:00 2024-10-06 00:00:00\n",
      "0.058140000000000004\n",
      "check : ProfitTake\n",
      "2024-09-20 00:00:00 2024-10-20 00:00:00\n",
      "0.048659999999999995\n",
      "check : ProfitTake\n",
      "2024-10-04 00:00:00 2024-11-03 00:00:00\n",
      "0.05018000000000001\n",
      "loss_cut: 0 profit_count: 0\n",
      "totalreturn: 13873.653629257813 asset: 38635.62109375 yield:13873.653629257813\n",
      "5.248345111876117\n",
      "2021-04-23 00:00:00 2021-05-23 00:00:00\n",
      "0.02\n",
      "check : ProfitTake\n",
      "2021-05-07 00:00:00 2021-06-06 00:00:00\n",
      "0.01848\n",
      "2021-05-21 00:00:00 2021-06-20 00:00:00\n",
      "0.02305\n",
      "check : ProfitTake\n",
      "2021-06-04 00:00:00 2021-07-04 00:00:00\n",
      "0.020780000000000003\n",
      "2021-06-18 00:00:00 2021-07-18 00:00:00\n",
      "0.0184\n",
      "2021-07-02 00:00:00 2021-08-01 00:00:00\n",
      "0.016850000000000004\n",
      "2021-07-16 00:00:00 2021-08-15 00:00:00\n",
      "0.01963\n",
      "2021-08-06 00:00:00 2021-09-05 00:00:00\n",
      "0.01955\n",
      "check : ProfitTake\n",
      "2021-08-20 00:00:00 2021-09-19 00:00:00\n",
      "0.02151\n",
      "check : ProfitTake\n",
      "2021-09-03 00:00:00 2021-10-03 00:00:00\n",
      "0.01929\n",
      "check : ProfitTake\n",
      "2021-09-17 00:00:00 2021-10-17 00:00:00\n",
      "0.02008\n",
      "2021-10-01 00:00:00 2021-10-31 00:00:00\n",
      "0.023940000000000003\n",
      "check : ProfitTake\n",
      "2021-10-15 00:00:00 2021-11-14 00:00:00\n",
      "0.02023\n",
      "check : ProfitTake\n",
      "2021-10-29 00:00:00 2021-11-28 00:00:00\n",
      "0.021880000000000004\n",
      "check : ProfitTake\n",
      "2021-11-12 00:00:00 2021-12-12 00:00:00\n",
      "0.019350000000000003\n",
      "2021-11-26 00:00:00 2021-12-26 00:00:00\n",
      "0.022330000000000003\n",
      "2021-12-10 00:00:00 2022-01-09 00:00:00\n",
      "0.02076\n",
      "check : ProfitTake\n",
      "2021-12-24 00:00:00 2022-01-23 00:00:00\n",
      "0.01879\n",
      "check : ProfitTake\n",
      "2022-01-14 00:00:00 2022-02-13 00:00:00\n",
      "0.0219\n",
      "2022-01-28 00:00:00 2022-02-27 00:00:00\n",
      "0.02706\n",
      "check : ProfitTake\n",
      "2022-02-18 00:00:00 2022-03-20 00:00:00\n",
      "0.02535\n",
      "2022-03-04 00:00:00 2022-04-03 00:00:00\n",
      "0.02799\n",
      "check : ProfitTake\n",
      "2022-03-18 00:00:00 2022-04-17 00:00:00\n",
      "0.02529\n",
      "check : ProfitTake\n",
      "2022-04-01 00:00:00 2022-05-01 00:00:00\n",
      "0.021270000000000004\n",
      "2022-04-15 00:00:00 2022-05-15 00:00:00\n",
      "0.02081\n",
      "2022-05-06 00:00:00 2022-06-05 00:00:00\n",
      "0.02773\n",
      "check : ProfitTake\n",
      "2022-05-20 00:00:00 2022-06-19 00:00:00\n",
      "0.02368\n",
      "check : ProfitTake\n",
      "2022-06-03 00:00:00 2022-07-03 00:00:00\n",
      "0.019010000000000003\n",
      "check : ProfitTake\n",
      "2022-06-17 00:00:00 2022-07-17 00:00:00\n",
      "0.02731\n",
      "check : ProfitTake\n",
      "2022-07-01 00:00:00 2022-07-31 00:00:00\n",
      "0.024410000000000005\n",
      "check : ProfitTake\n",
      "2022-07-15 00:00:00 2022-08-14 00:00:00\n",
      "0.021670000000000002\n",
      "check : ProfitTake\n",
      "2022-07-29 00:00:00 2022-08-28 00:00:00\n",
      "0.01893\n",
      "check : ProfitTake\n",
      "2022-08-12 00:00:00 2022-09-11 00:00:00\n",
      "0.018390000000000004\n",
      "check : ProfitTake\n",
      "2022-08-26 00:00:00 2022-09-25 00:00:00\n",
      "0.01872\n",
      "2022-09-09 00:00:00 2022-10-09 00:00:00\n",
      "0.01949\n",
      "2022-09-30 00:00:00 2022-10-30 00:00:00\n",
      "0.02633\n",
      "check : ProfitTake\n",
      "2022-10-14 00:00:00 2022-11-13 00:00:00\n",
      "0.02472\n",
      "check : ProfitTake\n",
      "2022-10-28 00:00:00 2022-11-27 00:00:00\n",
      "0.023700000000000002\n",
      "check : ProfitTake\n",
      "2022-11-11 00:00:00 2022-12-11 00:00:00\n",
      "0.02031\n",
      "2022-11-25 00:00:00 2022-12-25 00:00:00\n",
      "0.01749\n",
      "2022-12-09 00:00:00 2023-01-08 00:00:00\n",
      "0.01804\n",
      "2022-12-23 00:00:00 2023-01-22 00:00:00\n",
      "0.0202\n",
      "check : ProfitTake\n",
      "2023-01-06 00:00:00 2023-02-05 00:00:00\n",
      "0.01821\n",
      "check : ProfitTake\n",
      "2023-01-20 00:00:00 2023-02-19 00:00:00\n",
      "0.01737\n",
      "check : ProfitTake\n",
      "2023-02-03 00:00:00 2023-03-05 00:00:00\n",
      "0.01629\n",
      "check : ProfitTake\n",
      "2023-02-17 00:00:00 2023-03-19 00:00:00\n",
      "0.0154\n",
      "check : ProfitTake\n",
      "2023-03-03 00:00:00 2023-04-02 00:00:00\n",
      "0.016190000000000003\n",
      "check : ProfitTake\n",
      "2023-03-17 00:00:00 2023-04-16 00:00:00\n",
      "0.019450000000000002\n",
      "check : ProfitTake\n",
      "2023-03-31 00:00:00 2023-04-30 00:00:00\n",
      "0.01666\n",
      "check : ProfitTake\n",
      "2023-04-14 00:00:00 2023-05-14 00:00:00\n",
      "0.0166\n",
      "check : ProfitTake\n",
      "2023-04-28 00:00:00 2023-05-28 00:00:00\n",
      "0.015220000000000003\n",
      "check : ProfitTake\n",
      "2023-05-19 00:00:00 2023-06-18 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02007\n",
      "check : ProfitTake\n",
      "2023-06-02 00:00:00 2023-07-02 00:00:00\n",
      "0.020059999999999998\n",
      "check : ProfitTake\n",
      "2023-06-16 00:00:00 2023-07-16 00:00:00\n",
      "0.020739999999999998\n",
      "2023-06-30 00:00:00 2023-07-30 00:00:00\n",
      "0.019110000000000002\n",
      "2023-07-14 00:00:00 2023-08-13 00:00:00\n",
      "0.02049\n",
      "check : ProfitTake\n",
      "2023-07-28 00:00:00 2023-08-27 00:00:00\n",
      "0.01859\n",
      "check : ProfitTake\n",
      "2023-08-18 00:00:00 2023-09-17 00:00:00\n",
      "0.01952\n",
      "check : ProfitTake\n",
      "2023-09-01 00:00:00 2023-10-01 00:00:00\n",
      "0.01686\n",
      "check : ProfitTake\n",
      "2023-09-15 00:00:00 2023-10-15 00:00:00\n",
      "0.01599\n",
      "2023-09-29 00:00:00 2023-10-29 00:00:00\n",
      "0.0184\n",
      "check : ProfitTake\n",
      "2023-10-13 00:00:00 2023-11-12 00:00:00\n",
      "0.02097\n",
      "2023-10-27 00:00:00 2023-11-26 00:00:00\n",
      "0.02259\n",
      "check : ProfitTake\n",
      "2023-11-17 00:00:00 2023-12-17 00:00:00\n",
      "0.018280000000000005\n",
      "2023-12-01 00:00:00 2023-12-31 00:00:00\n",
      "0.016280000000000003\n",
      "2023-12-15 00:00:00 2024-01-14 00:00:00\n",
      "0.01734\n",
      "check : ProfitTake\n",
      "2023-12-29 00:00:00 2024-01-28 00:00:00\n",
      "0.017460000000000003\n",
      "check : ProfitTake\n",
      "2024-01-12 00:00:00 2024-02-11 00:00:00\n",
      "0.0224\n",
      "check : ProfitTake\n",
      "2024-01-26 00:00:00 2024-02-25 00:00:00\n",
      "0.01964\n",
      "check : ProfitTake\n",
      "2024-02-09 00:00:00 2024-03-10 00:00:00\n",
      "0.01925\n",
      "check : ProfitTake\n",
      "2024-03-01 00:00:00 2024-03-31 00:00:00\n",
      "0.020739999999999998\n",
      "check : ProfitTake\n",
      "2024-03-15 00:00:00 2024-04-14 00:00:00\n",
      "0.02033\n",
      "check : ProfitTake\n",
      "2024-03-29 00:00:00 2024-04-28 00:00:00\n",
      "0.018570000000000003\n",
      "2024-04-12 00:00:00 2024-05-12 00:00:00\n",
      "0.019969999999999998\n",
      "2024-04-26 00:00:00 2024-05-26 00:00:00\n",
      "0.02082\n",
      "check : ProfitTake\n",
      "2024-05-17 00:00:00 2024-06-16 00:00:00\n",
      "0.01679\n",
      "2024-05-31 00:00:00 2024-06-30 00:00:00\n",
      "0.01684\n",
      "check : ProfitTake\n",
      "2024-06-14 00:00:00 2024-07-14 00:00:00\n",
      "0.01629\n",
      "check : ProfitTake\n",
      "2024-06-28 00:00:00 2024-07-28 00:00:00\n",
      "0.01613\n",
      "check : ProfitTake\n",
      "2024-07-12 00:00:00 2024-08-11 00:00:00\n",
      "0.01837\n",
      "2024-07-26 00:00:00 2024-08-25 00:00:00\n",
      "0.0222\n",
      "check : ProfitTake\n",
      "2024-08-09 00:00:00 2024-09-08 00:00:00\n",
      "0.04528000000000001\n",
      "check : ProfitTake\n",
      "2024-08-23 00:00:00 2024-09-22 00:00:00\n",
      "0.025380000000000003\n",
      "2024-09-06 00:00:00 2024-10-06 00:00:00\n",
      "0.029070000000000002\n",
      "check : ProfitTake\n",
      "2024-09-20 00:00:00 2024-10-20 00:00:00\n",
      "0.024329999999999997\n",
      "check : ProfitTake\n",
      "2024-10-04 00:00:00 2024-11-03 00:00:00\n",
      "0.025090000000000005\n",
      "check : ProfitTake\n",
      "loss_cut: 0 profit_count: 0\n",
      "totalreturn: 8746.070976875002 asset: 38635.62109375 yield:8746.070976875002\n",
      "6.468199397734421\n",
      "last_losscut　：inf threshold :0.1 sharpratio : 6.468199397734421\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import math\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "i1 = 0\n",
    "sharp_ratio1 =0\n",
    "j1=0\n",
    "lis = []\n",
    "holder= []\n",
    "#schedule0 = pd.read_csv('data/RSI.csv', index_col='Date', parse_dates=True) \n",
    "#(1+np.cumsum(Price_day['N225'].pct_change().loc[df.index[0]:'2024-01-09', 'Close'])).plot()\n",
    "#(1+np.cumsum(data['Return'])).plot(label='{}, {}, {}'.format(threshold, threshold2, threshold3), legend=True)\n",
    "result =result.rename_axis('Date')                           \n",
    "for num in range(1):\n",
    "    sharp_ratio1=0\n",
    "    threshold, threshold2 = 50, 70\n",
    "    # (12, (0, 0), 1)\n",
    "    for threshold in [0.20, 0.10]:\n",
    "\n",
    "            #bond_leverage = 1\n",
    "            #ratio = ratio**(-1)\n",
    "            for a in [np.inf]:\n",
    "                    #for ratio_lev in range(66,67, 10):\n",
    "                    # threshold 40, threshold2 60 short \n",
    "                    loss_cut = 0.01 * a\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    dic = dict(schedule=pd.DataFrame(1, index=result.index, columns=['predict']),\n",
    "                            losscut=loss_cut,\n",
    "                            reverse=False,\n",
    "                            leverage=1, \n",
    "                            data2=N225,\n",
    "                            ratio=0,\n",
    "                            #bond_leverage=bond_leverage,\n",
    "                            threshold=threshold)\n",
    "\n",
    "                    \n",
    "                    _, df = calc(**dic)\n",
    "                    #(1+np.cumsum(df['Return'])).plot(label='{}'.format(threshold), legend=True)\n",
    "                    dic['losscut']=np.inf\n",
    "                    dic['schedule'] = pd.DataFrame([1 for u in range(len(result))], index=result.index, columns=['predict'])\n",
    "                    dic['reverse'] = False\n",
    "                    '''\n",
    "                    _, df2 = calc(**dic)  # 第４因数は、Falseの方がデフォです。\n",
    "\n",
    "                    data = df2.dropna(how='any', axis=0) #pd.concat([df, df2]).sort_index()\n",
    "                    try:\n",
    "                        (1+np.cumsum(data['Return'])).plot(label='Market'.format(), legend=True)\n",
    "                    except:\n",
    "                        continue\n",
    "                    try:\n",
    "                        dd = Drawdown(df2['Return'])\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        continue\n",
    "                    '''\n",
    "                    data = df\n",
    "                    (1+np.cumsum(data['Return'])).plot(label='{}'.format((a, threshold)), legend=True)\n",
    "                    sharp_ratio = np.mean(data['Return'].values) /np.std(data['Return'], ddof=1)\n",
    "                    print(sharp_ratio)\n",
    "                    \n",
    "                    lis.append(sharp_ratio)\n",
    "                    if sharp_ratio > sharp_ratio1:\n",
    "\n",
    "                        last_losscut = a\n",
    "\n",
    "                        sharp_ratio1 = sharp_ratio\n",
    "                        pair=(threshold)\n",
    "\n",
    "\n",
    "\n",
    "    holder.append(pair)\n",
    "\n",
    "print(\n",
    "    f\"last_losscut　：{last_losscut}\",   \n",
    "    #f\"last_profitlevel : {last_profitlevel} \",\n",
    "    f\"threshold :{pair}\",\n",
    "    f\"sharpratio : {sharp_ratio1}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Return</th>\n",
       "      <th>loss_cut</th>\n",
       "      <th>profit</th>\n",
       "      <th>Asset</th>\n",
       "      <th>Exit Date</th>\n",
       "      <th>日数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-07</th>\n",
       "      <td>-0.037184</td>\n",
       "      <td>safe</td>\n",
       "      <td>-1091.647910</td>\n",
       "      <td>29357.820312</td>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-16</th>\n",
       "      <td>0.057994</td>\n",
       "      <td>safe</td>\n",
       "      <td>1623.998957</td>\n",
       "      <td>28003.080078</td>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-17</th>\n",
       "      <td>-0.033252</td>\n",
       "      <td>safe</td>\n",
       "      <td>-1014.191507</td>\n",
       "      <td>30500.050781</td>\n",
       "      <td>2021-10-17</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-10</th>\n",
       "      <td>-0.042810</td>\n",
       "      <td>safe</td>\n",
       "      <td>-1217.413009</td>\n",
       "      <td>28437.769531</td>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-04</th>\n",
       "      <td>-0.009551</td>\n",
       "      <td>safe</td>\n",
       "      <td>-248.183607</td>\n",
       "      <td>25985.470703</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>-0.031589</td>\n",
       "      <td>safe</td>\n",
       "      <td>-893.423049</td>\n",
       "      <td>28283.029297</td>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03</th>\n",
       "      <td>0.023098</td>\n",
       "      <td>safe</td>\n",
       "      <td>635.405603</td>\n",
       "      <td>27509.460938</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-19</th>\n",
       "      <td>0.067165</td>\n",
       "      <td>safe</td>\n",
       "      <td>2069.254873</td>\n",
       "      <td>30808.349609</td>\n",
       "      <td>2023-06-18</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-14</th>\n",
       "      <td>0.005110</td>\n",
       "      <td>safe</td>\n",
       "      <td>165.517377</td>\n",
       "      <td>32391.259766</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-15</th>\n",
       "      <td>-0.002863</td>\n",
       "      <td>safe</td>\n",
       "      <td>-96.016278</td>\n",
       "      <td>33533.089844</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-09</th>\n",
       "      <td>0.031602</td>\n",
       "      <td>safe</td>\n",
       "      <td>1166.042478</td>\n",
       "      <td>36897.421875</td>\n",
       "      <td>2024-03-10</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15</th>\n",
       "      <td>0.009780</td>\n",
       "      <td>safe</td>\n",
       "      <td>378.546763</td>\n",
       "      <td>38707.640625</td>\n",
       "      <td>2024-04-14</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-23</th>\n",
       "      <td>-0.012179</td>\n",
       "      <td>safe</td>\n",
       "      <td>-467.227935</td>\n",
       "      <td>38364.269531</td>\n",
       "      <td>2024-09-22</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Return loss_cut       profit         Asset  Exit Date  日数\n",
       "2021-05-07 -0.037184     safe -1091.647910  29357.820312 2021-06-06  69\n",
       "2021-07-16  0.057994     safe  1623.998957  28003.080078 2021-08-15  68\n",
       "2021-09-17 -0.033252     safe -1014.191507  30500.050781 2021-10-17  69\n",
       "2021-12-10 -0.042810     safe -1217.413009  28437.769531 2022-01-09  69\n",
       "2022-03-04 -0.009551     safe  -248.183607  25985.470703 2022-04-03  69\n",
       "2022-11-25 -0.031589     safe  -893.423049  28283.029297 2022-12-25  69\n",
       "2023-02-03  0.023098     safe   635.405603  27509.460938 2023-03-05  69\n",
       "2023-05-19  0.067165     safe  2069.254873  30808.349609 2023-06-18  69\n",
       "2023-07-14  0.005110     safe   165.517377  32391.259766 2023-08-13  69\n",
       "2023-09-15 -0.002863     safe   -96.016278  33533.089844 2023-10-15  68\n",
       "2024-02-09  0.031602     safe  1166.042478  36897.421875 2024-03-10  69\n",
       "2024-03-15  0.009780     safe   378.546763  38707.640625 2024-04-14  69\n",
       "2024-08-23 -0.012179     safe  -467.227935  38364.269531 2024-09-22  63"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-23</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-07</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-09</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-23</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-20</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            predict\n",
       "Date               \n",
       "2021-04-23      0.0\n",
       "2021-05-07      1.0\n",
       "2021-05-21      0.0\n",
       "2021-06-04      0.0\n",
       "2021-06-18      0.0\n",
       "...             ...\n",
       "2024-08-09      0.0\n",
       "2024-08-23      1.0\n",
       "2024-09-06      0.0\n",
       "2024-09-20      1.0\n",
       "2024-10-04      0.0\n",
       "\n",
       "[86 rows x 1 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in Price_day.iterrows():\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('オミットデータサンプル2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for threshold in [40]:\n",
    "        for threshold2 in [50]:\n",
    "            for threshold3 in [38]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1+np.cumsum(Price_day['N225'].pct_change().loc['2009-05-28':'2024-01-09', 'Close'])).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70 -> 30 OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule0.query('rsi9>=60').diff().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No hedge\n",
    "graph(df, False, './graph_image/Nikkei_future_3moNeo', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(df):\n",
    "    Sel = pd.Series()\n",
    "    Sel['初期資金'] = df['open_price'][0]\n",
    "    \n",
    "    Sel[\"全トレード数\"] = df.shape[0]\n",
    "    #print((10**2) * df.query('interest >= 0').count() / df.shape[0])\n",
    "    Sel[\"勝率\"] = \"{:.2f}%\".format((10**2) * df.query('interest >= 0').shape[0] / df.shape[0])\n",
    "    Sel[\"負率\"] = \"{:.2f}%\".format((10**2)* df.query('interest < 0').shape[0] / df.shape[0])\n",
    "    Sel[\"全トレード平均利益\"] = df['interest'].mean()\n",
    "    Sel[\"勝ちトレード平均利益\"] =  df.query('interest >= 0')['interest'].mean()\n",
    "    Sel[\"負けトレード平均利益\"] =  df.query('interest < 0')['interest'].mean()\n",
    "    \n",
    "    Sel[\"プロフィットファクター\"] = df.query('interest >= 0')['interest'].sum() / -df.query('interest < 0')['interest'].sum()\n",
    "    \n",
    "    display(pd.DataFrame(Sel))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(df['interest'], bins=20, label='interest')\n",
    "Evaluation(df.query('signal!=1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
